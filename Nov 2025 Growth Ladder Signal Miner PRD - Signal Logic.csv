,,,,,,,
,#,Bucket,Question,Category,Why This Question Matters,MVP Answer (Internal Tool),Post-MVP Answer (Full SaaS & Platform)
,1,Signal Creation & Lifecycle,Are signals global/shared or private to each organisation?,Signal Ownership,"This determines whether one signal definition can be reused across many customers or whether each workspace has its own “copy.” It affects database design (tenant scoping), compute reuse, and how personalization works. Getting this wrong early can cause painful refactors later when you introduce multi-tenancy and marketplaces.","Private to each workspace. In MVP, every signal definition lives inside a single GL client workspace. You treat signals as part of that client’s configuration, not as global assets. This keeps things simple and avoids cross-tenant complexity while you’re still discovering what a “good” signal looks like.","Still private at the data level, but templated globally. You introduce global “signal templates” and vertical packs, but each workspace installs/overrides them, creating a tenant-specific instance. No signal instance is shared across orgs, only the template metadata is."
,2,Signal Creation & Lifecycle,Can a business create custom signal types?,Customization,"This decides whether your system is a fixed catalogue of signals (like a productized BirdDog) or a flexible engine teams can extend. It influences the UX, prompt design, and schema (rigid vs dynamic). Without custom signals, enterprise or niche verticals will quickly hit a ceiling.","Yes, but via simple admin UI / config panels. MVP lets user define custom signals using simple structured fields (name, description, logic fields, example phrases). No fancy visual builders; just basic forms ","Yes, with a richer “signal builder” UI a. Later, users can define custom signals using a proper builder and natural language"
,3,Signal Creation & Lifecycle,"If two businesses create the same custom signal, do we duplicate it?",Deduplication,"If every similar signal is stored separately, you may end up with thousands of near-identical definitions, making maintenance harder. On the other hand, aggressively deduping can over-couple very different customers. You need a clear conceptual separation between global templates and workspace instances.","Treat as separate, duplicated definitions. In MVP, custom signals are entirely workspace-scoped, even if they look similar. You optimise for simplicity and avoid any cross-workspace logic or global catalog responsibilities.","Template-level deduplication, instance-level separation. You later introduce a “template ID” for similar signals and treat each workspace’s configuration as a derivative instance. Templates can be updated centrally, but each workspace has override capabilities."
,4,Signal Creation & Lifecycle,What is the lifecycle of a signal?,Signal Lifecycle,"Developers need a state diagram to avoid spaghetti logic. Without a defined lifecycle, you’ll end up with ad hoc flags and bugs (e.g., stale signals, half-created signals). Product decisions like “can we archive?” or “do we support drafts?” all hang off this.","Simple lifecycle: Created → Active → Archived. In MVP, a signal is created (definition stored), then immediately participates in future ingestion runs and on previous 90 day store source data.","Full lifecycle: Draft → Active → Updating → Deprecated → Archived. Later, you add draft mode, versioned updates (while still active), and explicit deprecation/archival states, with audit history and analytics around usage."
,5,Signal Creation & Lifecycle,Are signals static or dynamic (recomputed as data changes)?,Computation Strategy,"Dynamic signals are more powerful but more expensive (compute/LLM) and harder to reason about. Static signals are cheaper but may become stale. This decision touches ingestion pipelines, caching, and cost modeling.",Dynamic based-off a predefined run schedule,"Dynamic with incremental updates. Later, you support event-driven updates – when a source changes or new context appears, the signal object is updated (e.g., status, stage) and those changes are visible in timelines and alerts."
,6,Signal Creation & Lifecycle,What happens when a source changes after a signal was already emitted?,Source–Signal Linking,"If a tender is amended, canceled, or updated, your signal needs to reflect that or it becomes misleading. Handling deltas is more complex than just re-scraping and overwriting.",Re-evaluated only on next scheduled run. MVP does not track diffs; it just treats the latest scrape as the truth and updates the signal’s core fields on the next cycle. Internal GL users understand that this is a batch system.,"Incremental updates with change tracking. In the platform, you track version changes and emit updates (e.g., “tender extended” or “value increased”). You may show a timeline of changes, and notifications can be triggered when key fields change."
,7,Signal Creation & Lifecycle,Is “Why It Matters” regenerated every time new data appears?,LLM Cost Model,This is one of the biggest levers in your cost and response time. Regenerating on every source change can explode token usage; never regenerating can make explanations stale or wrong.,"Generated once per signal at first creation. For MVP, WIM is created when the signal is first formed and is not automatically re-run unless you explicitly trigger it in internal tools. This keeps LLM usage predictable and low.","Regenerated conditionally based on material changes. Later, you implement change thresholds (e.g., new stage, new project value) where WIM is updated and a new version is stored. For minor changes, the old WIM is reused."
,8,Signal Creation & Lifecycle,Should signals include historical snapshots or only show the latest state?,History & Audit,"History supports “what changed when,” campaign retros, and compliance questions. It increases storage and complexity but is invaluable for analytics and trust.",Supports the last 90 days of source data,"Yes, with structured event history. Post-MVP, each material update generates a new event or revision: created, updated, closed, etc. Timelines appear in the UI so users can see signal evolution."
,9,Signal Creation & Lifecycle,"Can two signals conflict (e.g., one says “great opportunity,” another “high risk”)?",Consistency & UX,"Conflicting signals can confuse users and make them distrust the system. You need some rules around precedence, visibility, or labelling so reps know which one to act on.","MVP: allow conflict, rely on human interpretation. You don’t try to solve conflict resolution at the system level initially; users are expected to interpret conflicting cues.","Introduce conflict detection and resolution heuristics. Later, you add label rules (e.g., negative risk flags visually override some positive ones, or you surface a “mixed signal” status with explanation)."
,10,Signal Creation & Lifecycle,How should signals be sorted by default in the feed?,Prioritisation Logic,"Default sort heavily influences how users experience the product and what they actually work on. It must align with business value (e.g., recency + relevance) not just “latest scraped.”","Sort by recency + a simple “importance” score (e.g., recency + high/medium/low). MVP uses a very basic formula; internal GL can also manually filter to refine.","Use a composite score (recency × relevance × ICP fit × impact). Later, you implement a proper scoring model and allow user-configurable sort options and presets, including vertical-specific rankers."
,11,Signal Personalization (Why It Matters),Is “Why It Matters” business-specific or shared?,Personalisation Strategy,"If WIM is always generic, you’re just a data scraper. If it’s business-specific, you become a strategic co-pilot. This affects whether you must store per-org WIM and how LLM prompts look.","Business-specific per workspace. For MVP, each workspace gets WIM generated using that company’s website + high-level context so even internal GL-only usage reflects client strategy.","Richer per-business WIM using deeper context. Post-MVP, WIM incorporates ICP definitions, vertical packs, and maybe CRM information to explain “why it matters specifically for your go-to-market motion.”"
,12,Signal Personalization (Why It Matters),What business context is used to personalize WIM?,Context Model,"You can plug in basic context (website text) or richer structured data (ICP filters, target personas, solution areas). More context = better relevance but more data modelling.","Use website, industry, and a short “about this client” field. MVP scrapes the company’s website and the simple ""company details"" onboarding form information","Add ICP, buyer personas, product lines, geographic focus, and campaign goals. The platform will support a richer “account config” model that informs WIM and action suggestions."
,13,Signal Personalization (Why It Matters),Does WIM depend on vertical packs?,Vertical Intelligence,"Vertical packs allow you to encode specialised logic (e.g., construction, healthcare). If WIM doesn’t leverage these, you’re underusing that future asset.",No vertical pack logic initially. MVP uses generic reasoning; any industry nuance is injected manually by GL via context.,"Yes – vertical packs adjust language, key fields, and “why it matters” framing. For example, a healthcare pack emphasises compliance and patient throughput; a construction pack emphasises project timeline and capex."
,14,Signal Personalization (Why It Matters),"Will LLM consider company goals (e.g., “we sell CCTV to new developments”) when generating WIM?",Deeper Personalisation,"This is what lets the system say “This matters because this site will need cameras and you sell those,” not just “there’s a development.”","Use a simple “ICP” field per client. MVP adds one custom field: “Target ICP"" which can be incorporated into prompts.","Use a structured goal/solution model. Later, clients define solution areas (e.g., “sell access control to large commercial builds”), which the LLM uses to tailor WIM and recommended actions."
,15,Signal Personalization (Why It Matters),"If two customers subscribe to the same signal template, do they get the same summary?",Multi-tenant Output,"Sharing summary but customising WIM is a key cost optimization: one summarisation, many context-specific explanations.","Yes: global summary, workspace-specific WIM. MVP generates one “what happened” summary globally and then a per-workspace WIM.","Same design, more optimised. Post-MVP YOU keep this pattern but add caching and template-level reuse so many workspaces can share base summaries."
,16,Signal Personalization (Why It Matters),Should WIM consider the company’s competitive differentiation?,Positioning,"This lets you say “You have unique capabilities in X; this signal suggests a buyer who needs X,” making WIM feel like a strategic consultant.","Not in MVP. You don’t parse “differentiation” separately; website text and a short description are used, but no explicit competitor-aware logic.","Yes later – via an optional “positioning profile.” You support fields like “We are cheaper/faster/more integrated than X,” and WIM uses that to frame opportunity and angle."
,17,Signal Personalization (Why It Matters),Should WIM propose next actions?,Actionability,"If WIM includes “what to do next,” you cross the line into outbound orchestration, which is your long-term vision. It makes the product much more valuable but couples it to AISDR.","No for MVP. You keep WIM descriptive (“why it matters”) not prescriptive (“do this sequence”), and GL handles next steps manually in Airtable/Clay.","Yes, as “Next Best Action.” Later, WIM includes a short recommended play (e.g., “Add to ‘New Development – CCTV’ sequence” or “Send direct mail to facilities director”) which can be mapped to flows."
,18,Signal Personalization (Why It Matters),Can users edit WIM?,UX Control,"Editing WIM lets power users correct odd phrasings or include customer-specific nuance. However, it introduces versioning and training questions.",No editing in MVP. WIM is read-only; use signal notes if they want to add commentary. This avoids having to handle LLM retraining logic.,"Editable with audit history. In the platform, users can edit WIM; original AI output is preserved, and edits can optionally feed back into future prompt fine-tuning."
,19,Sources & Ingestion,Are sources global or workspace-specific?,Source Tenancy,Global ingestion is cheaper and easier for cross-customer reuse; workspace-specific ingestion allows private sources. You need clarity to avoid re-implementing ingestion later.,"Global ingestion pipeline (i.e. sources ingested are available to all users of the platform). MVP scrapes each public source once and stores it, then uses that data across all workspaces for signal evaluation. This keeps costs manageable.","Hybrid model. Post-MVP you still have global sources, but also support workspace-specific sources (e.g., private bid portals, customer’s internal RSS) that only that tenant sees."
,20,Sources & Ingestion,Can multiple sources trigger the same signal?,Multi-Source Signals,"Projects often appear across multiple sources; if you don’t unify them, you generate noise and duplicates, which confuse users.","If the same signal appears across multiple sources, de-dupe and consolidate i.e. show the 1 signal and include supporting sources A B C","Unify into a single signal with multiple source references. Later, a signal can carry an array of sources that contributed evidence; you deduplicate based on text similarity, entity matching, and structure."
,21,Sources & Ingestion,"If multiple sources trigger a signal, does WIM change?",WIM Aggregation,"Different sources can add nuance (e.g., tender details, budget, stakeholders). Your explanation should ideally incorporate all, not just the first.","No multi-source WIM in MVP. Because you’re not merging sources in MVP, each signal is tied to a single source and WIM references only that.","Yes – WIM is recomputed based on the combined context. When you unify sources, the LLM takes the merged context and explains the bigger picture: “Across 3 sources, here’s what’s happening and why it matters.”"
,22,Sources & Ingestion,Should a signal store which source triggered it?,Transparency & Trust,"Users will ask “Where did this come from?” If you can’t show them the underlying page or reference, trust plummets.","Yes – store and surface source URL, title and snippet. MVP shows at least a link back to the raw page, so GL can validate.","Yes, with full lineage. Later you show multiple sources, timestamps, and which fields came from where, possibly in a “source panel” for each signal."
,23,Sources & Ingestion,How often are sources refreshed?,Ingestion Cadence,Refresh cadence directly drives infrastructure cost and product freshness. Different industries may need different cadences.,"Daily batch ingestion (starting Sunday). For MVP you run one daily job, maybe a second if essential. However, if this blows out costs then we can reassess","Configurable cadences. You support workspace-level or source-level settings (e.g., hourly for critical tender feeds, daily for news). Premium tiers can get higher frequency."
,24,Sources & Ingestion,"What happens when a source breaks (HTML change, 404, anti-bot)?",Error Handling,"Broken scrapers silently degrade product value. You need a strategy for detection, logging, and ideally alerting, even if only internal at first.",Internal logging only. MVP logs failures in a dev dashboard; GL then monitors and fixes  key sources. No user-facing error messaging yet.,"Full monitoring and alerting. Post-MVP you have a feed health dashboard, alerts to your ops/dev team, and potentially user-facing badges (“Feed temporarily delayed”)."
,25,Sources & Ingestion,Do users see all available sources or only their own subset?,Source UX,Too many sources makes onboarding noisy; too few reduces perceived value. You also need to prevent confusion over sources that don’t apply to a client’s geography or vertical.,User configures what sources they want the signal to monitor and can request new sources ,Users will be able to pay for premium sources and have basic access to generic sources
,26,Sources & Ingestion,Should ingestion use full text or summaries/embeddings?,LLM & Storage Cost,Full-text storage and processing is expensive and slow. Summaries and embeddings are cheaper but may omit critical nuance.,Summarise and store only essential structured fields + short summary. MVP scrapes full text but stores a compact representation for LLM and search; full pages can be referenced via URLs.,"Hybrid architecture. Long term, you keep embeddings and structured fields in your DB but may rely on vector DBs or object storage for full raw HTML/text, depending on use case."
,27,Sources & Ingestion,How do we handle credentialed or paid sources?,Compliance & Security,"Accessing logged-in or paid portals has legal, ethical, and security implications. It needs a robust auth story and terms compliance.","MVP: no authenticated or paid sources. Stick to public, no-login data until product-market fit is proven.","Workspace credential vault. Later, customers can add credentials for their own licensed sources (e.g., a private tender portal), stored securely and used only for that workspace."
,28,Sources & Ingestion,Can customers request new sources?,Operations & Scope,Allowing custom source requests unlocks value but also loads you with manual work unless carefully scoped.,"Yes, but manually via GL. MVP expects GL to funnel requests; developers add new sources as needed on a case-by-case basis with no formal SLA.","Formal source request flow with SLA. In the SaaS product, admins can request sources via a form; you triage and add them according to vertical/impact (e.g., 48-hour SLA for certain tiers)."
,29,Multi-tenancy & Data Isolation,Should businesses be isolated workspaces like tenants?,Data Architecture,"This is the fundamental multi-tenant vs single-tenant design choice. Everything (IDs, queries, security) flows from it.","Yes – strict workspace isolation (workspace_id). MVP treats each client as a separate logical tenant, even if all data sits in one DB.","Yes, with multi-tenant admin features later. You maintain workspace isolation, adding features like cross-workspace management for agencies or large enterprises."
,30,Multi-tenancy & Data Isolation,Do users within the same org see all signals or only their own?,Internal Sharing,"Shared vs personal views influences coordination and complexity. In sales teams, shared context usually wins.",All users in a workspace see all signals. MVP is simple: a shared signal feed per client; you avoid per-user scoping logic.,"Configurable access scopes. Later, you allow signals to be filtered by team, territory, or pipeline, but they’re still within the same workspace by default."
,31,Multi-tenancy & Data Isolation,Can a user make a private signal only they see?,Privacy & UX Complexity,"Private signals can be useful in large orgs, but they complicate logic and can create weird experiences (“why can’t I see that?”).",Not in MVP. Every signal is workspace-wide; internal GL can maintain private notes externally if needed.,"Optional private signals for advanced orgs. In the full platform, allow private signals for power users, but default is shared."
,32,Multi-tenancy & Data Isolation,How is a signal linked to a workspace?,Data Schema,This is a core schema decision: where does tenant scoping live in your data model?,Signal table includes a workspace_id foreign key. All queries always scoped by this ID in the backend.,"Same design, extended with global template references. You add template_id to link signals to global templates, but workspace_id remains first-class."
,33,Multi-tenancy & Data Isolation,What happens when a user deletes a signal definition?,Deletion Semantics,"Hard vs soft delete affects UX, trust, and analytics. You don’t want accidental deletion to destroy important data.",Soft delete with a simple flag. MVP marks signals as deleted/archived but doesn’t physically remove rows; they disappear from the main feed.,"Soft delete + recovery + full audit. Post-MVP, you keep revision history so admins can restore or inspect who deleted what and when."
,34,Multi-tenancy & Data Isolation,Do we require role-based access control (RBAC)?,Security & Governance,"RBAC is key for enterprise readiness, but heavy RBAC is overkill in an MVP. You need to choose a minimal viable model.","Basic roles only (admin, member). MVP: admins can manage signals and sources; members can view and maybe annotate signals.","Full RBAC with granular permissions. Later, you introduce roles like admin, manager, rep, read-only, plus SCIM-based provisioning for enterprises."
,35,Multi-tenancy & Data Isolation,Should each workspace have an owner?,Governance & Billing,"Ownership is important for billing, support, and account recovery. Without a single owner, admin confusion arises.",Yes – one “workspace owner” required. MVP uses a single owner who can manage members and owns billing (when you add it).,"Multiple owners and admin roles. Later, enterprise customers can have several owners/admins, with a clear hierarchy and replacement rules."
,36,Multi-tenancy & Data Isolation,When is the LLM called in the signal pipeline?,Cost & Latency,"Deciding whether LLM is used at ingest time, at view time, or on demand radically affects architecture and perceived speed.","At signal creation time, during ingest. MVP calls LLM only as part of ingestion to classify, summarise, and create WIM. Nothing is done lazily at view-time.","Hybrid: ingest-time for core classification; view-time for advanced summarisation when needed. For some interactions, you might generate extra elaboration only when a user actually opens the signal."
,37,AI/LLM Behaviour & Cost,Can we summarise each source once and reuse for all signals?,Optimisation Strategy,"Reusing summaries is the main lever to avoid duplicated LLM work across tenants; without it, costs explode as you scale.",Yes – summarise globally once. MVP stores a “base summary” per source that can be reused for multiple signals and tenants.,"Yes, and also store structured extracted fields and embeddings for reuse. Future versions add richer reuse so multiple signal types can share the same parsed representation."
,38,AI/LLM Behaviour & Cost,Is classification LLM-based or rules-based?,Accuracy vs Cost,Rules are cheap but brittle; LLM classification is flexible but more expensive. A hybrid strategy often works best.,"Rules-first; LLM as a fallback. MVP uses simple keyword patterns and heuristics for most classification, with an occasional LLM call when rules aren’t confident.","Hybrid with ML + LLM. Later, you build a proper classifier (ML model) with LLM support, retrained on past decisions and feedback."
,39,AI/LLM Behaviour & Cost,Does every LLM call use business context?,Prompt Design,Injecting context improves quality but increases token usage and coupling to that context schema.,"Yes, but only minimal context. MVP passes in a short “about this business” and website snippet to keep prompts small.","Yes, with richer structured context. Post-MVP, prompts include ICP data, solution focus, vertical pack, and buyer personas."
,40,AI/LLM Behaviour & Cost,Are prompts static or dynamic?,Maintainability,Static prompts are easy to manage but less adaptable; dynamic prompts require more design work but allow vertical and customer nuance.,"One static prompt per task (classification, summary, WIM). MVP hardcodes prompts in config so changes are easy and consistent.","Composable prompt framework. Later, prompts are constructed from reusable components (base + vertical + workspace overrides), potentially editable in admin UIs."
,41,AI/LLM Behaviour & Cost,Do we log LLM I/O for debugging?,Observability,"Without logs, you cannot understand misclassifications or weird outputs; with logs, you have compliance and privacy concerns.","Yes, log I/O internally. MVP stores LLM inputs/outputs in an internal log table for debugging only, not exposed to end users.","Yes, with controlled retention and access. In the platform, logs are still kept but with retention policies, and parts might be exposed in a “Why did we decide this?” diagnostics view."
,42,AI/LLM Behaviour & Cost,How do we prevent hallucinations?,Reliability,"Hallucinations can create false signals or wrong summaries, damaging trust. Guardrails and validation are required.","Constrain with schema and simple checks. MVP uses strong instructions (“only from text”) and validates outputs (e.g., require valid JSON, certain fields) before acceptance.","Add retrieval-augmented generation and guardrails. Later, LLM outputs are grounded in stored source text and validated against schemas and deterministic checks."
,43,AI/LLM Behaviour & Cost,Which model(s) do we use?,Future-Proofing,"Choice of model affects cost, latency, and quality. You may want to swap models later or support multiple vendors.","Use GPT-4.1-mini / GPT-4o-mini equivalents. MVP uses one cost-efficient, capable model for all tasks to keep complexity down.","Support multiple providers and model families. Longer-term, you allow per-task/per-tenant model selection and possibly on-prem or local models for large enterprise deals."
,44,AI/LLM Behaviour & Cost,Do outputs need to be deterministic?,UX Consistency,"If users see different text each time they open a signal, they may be confused or mistrustful.","Yes, aim for near-deterministic outputs. MVP uses low temperature and avoids re-running prompts unnecessarily, so content is stable.","Mostly deterministic for core fields, flexible for commentary. In the platform, critical fields are stable; optional “extra insights” can be more creative/variable."
,45,AI/LLM Behaviour & Cost,Who can create signals?,UX & Governance,"If anyone can create signals, they might flood the system with noise; if only admins can, teams may move slowly.",Admins only. MVP restricts creation to GL or workspace owner-level roles so you preserve quality and avoid clutter.,"Admins + power users. Later, you add a “builder” role for advanced users and maybe an approval flow for newly created signals."
,46,Configurability & UI Logic,How are signals grouped in the UI?,Information Architecture,Grouping affects how quickly users can find relevant signals. Poor grouping yields a cluttered experience.,"Grouped by either signal type (e.g., CAPEX, Hiring, Regulatory), or signal campaign name. User has the ability to filter/slice/dice signal view","Grouped by category, vertical, and tags. Post-MVP, you support finer categories, vertical tags (e.g., Construction/Healthcare), and user-defined tags."
,48,Configurability & UI Logic,Can signal campaigns be paused/archived/snoozed?,State Management,"Users often want to temporarily suppress a signal without deleting it permanently (e.g., irrelevant this quarter).",Basic archive only. MVP provides a simple “active/archived” toggle; archived signals no longer run or appear in feed.,"Full state controls: pause, snooze, archive. Later, you allow snoozing for defined periods and reactivation, plus archive for long-term retirement."
,49,Configurability & UI Logic,Do signals appear instantly after signal campaign creation?,UX Expectations,"If a user creates a signal and sees nothing, they may think it’s broken. You need a predictable mental model.","Since data is already stored (GL builds sources, not a user), the ""prompting"" of that data to create the signal campaign happens immediately but can take X minutes to be finalised. So long as we inform the user that the campaign building is underway","Show a placeholder immediately. In the platform, you show newly created signals as “awaiting data” with status and expected time for first run."
,50,Configurability & UI Logic,How are “new since last login” signals handled?,Engagement,Surfacing “new” makes the product feel alive and draws users back regularly.,Bell icon in top right works well,Implemented via per-user read markers. The platform tracks when each user last visited and highlights new/updated signals accordingly.
,51,Configurability & UI Logic,"Should signals have severity levels (e.g., high/medium/low)?",Prioritisation,Severity is a simple mental model for focusing; many sales workflows rely on it.,Yes – simple high/medium/low flag. MVP uses an manually or rule-assigned severity field used in sorting/filtering.,"Yes – plus computed composite score. Later, severity is derived from underlying signals and ICP fit; users can still override in some cases."
,52,Configurability & UI Logic,Are saved filters/views supported?,Scalability of UX,"As signal volume grows, saved views are necessary to manage complexity across clients, reps, or campaigns.",Yes for internal GL analysts only. MVP has a simple saved filter mechanism for GL team; no polished UI needed.,"Yes for all users with sharing. In the full platform, each user/team can create and share saved views for their workflows (e.g., “ANZ Construction Tenders > $2M”)."
,53,Configurability & UI Logic,How is relevance scored?,Scoring Engine,This is the foundation of ranking and what surfaces to the top. It can be simple rules or complex models.,Simple hybrid: keyword frequency + some semantic similarity. MVP uses basic scoring based on term matches and a crude embedding similarity check.,"Full relevance model. Later, you train a relevance model on user feedback and performance data, combining embeddings, signal type, vertical, and ICP fit."
,54,"Scoring, Relevance & Matching Logic",Does relevance differ per business (contextual)?,Personalisation,"Different customers will care about different patterns, even on the same data. Context-aware relevance is an unlock.",Not in MVP. Relevance is global; GL manually interprets which signals matter more to a given client.,"Yes – per-workspace relevance weighting. The platform lets each workspace define ICP/priority rules that feed into the relevance model, making the same raw signal more or less important by client."
,55,"Scoring, Relevance & Matching Logic",Can signals belong to multiple categories?,Multi-Label Classification,Multi-category support enables powerful filtering (“show CAPEX + sustainability”) but adds complexity.,No – one primary category per signal. MVP keeps it simple: each signal has a single category.,"Yes – multi-label classification. Later each signal can carry multiple tags/categories (CAPEX + ESG + Hiring), which improve filter power."
,56,"Scoring, Relevance & Matching Logic",Is ranking different for different industries?,Vertical Scoring,"Different verticals may need different weighting (e.g., recency vs budget vs location).",Not in MVP. MVP uses the same simple scoring logic across all verticals.,"Yes in verticalised packs. Later, vertical packs include scoring rules; for example, construction emphasises stage-of-project and contract value."
,57,"Scoring, Relevance & Matching Logic",Can users override relevance scores manually?,User Control,Allowing manual overrides helps handle exceptions but can create drift if overused.,Not in MVP. Users can’t change underlying scores; they adjust via filters and note fields.,"Yes with controlled overrides. In the platform, advanced users can adjust weights or manually boost/suppress certain accounts/signals, which feeds back into the scoring logic."
,58,"Scoring, Relevance & Matching Logic",How are low-confidence signals handled?,Quality Control,Presenting too many low-confidence signals clutters the feed and erodes trust.,Threshold-based suppression. MVP only surfaces signals above a simple confidence threshold; others are dropped or kept hidden in an internal log.,"Confidence-aware UX controls. Later, you allow users to tweak thresholds per view and optionally show low-confidence items in secondary tabs for power users."
,59,"Scoring, Relevance & Matching Logic",Can users publish their own signal packs publicly?,Marketplace,"A marketplace of user-created packs is a key network effect and moat, but brings moderation and quality challenges.",No. MVP has no concept of public packs; all signal definitions are internal or GL-created for specific clients.,"Yes, curated marketplace. Long term, partners and power users can publish vetted packs, with GL controlling listing, pricing, and verification."
,60,Future-proofing (Marketplace & Vertical Packs),Do vertical packs modify prompts and logic?,Verticalisation,"If vertical packs don’t affect prompts and scoring, they’re mostly cosmetic. Real value comes from vertical-specific intelligence.","No vertical packs in MVP. You might internally think in vertical terms, but the system doesn’t.","Yes – vertical modules change prompts, scoring, and relevant fields. A construction pack changes how project signals are summarised; healthcare pack changes WIM to emphasise compliance and patient funnel, etc."
,61,Future-proofing (Marketplace & Vertical Packs),Can packs be installed per workspace?,Feature Modularity,Different customers will want different packs; this defines how you ship features and manage licensing.,Not applicable in MVP. No explicit pack system; GL manually configures each workspace.,"Yes – install/uninstall packs per workspace. Packs can be added from a library and define new signals, sources, scoring rules, and fields."
,62,Future-proofing (Marketplace & Vertical Packs),"Do packs include filters, views, and presets?",Pack Design Depth,"The richer the pack, the faster customers reach value and the higher the willingness to pay.",No – MVP packs (if any) are conceptual only. GL manually sets up views for clients; nothing is packaged inside the tool.,"Yes – packs include filters, saved views, categories, and dashboards. Installing a pack can auto-create useful default workspaces for that vertical."
,63,Future-proofing (Marketplace & Vertical Packs),Can packs override global signal categories?,Governance,"If packs can override categories, you need a governance layer to prevent chaos and conflicting labels.",No. MVP uses a single global category schema.,"Yes but with guardrails. Packs can extend/rename categories within their workspace’s context, but you maintain internal canonical mappings."
,64,Future-proofing (Marketplace & Vertical Packs),What is the billing / pricing model?,Business Model,"Pricing shapes feature design (e.g., per seat vs per signal vs per AI call). It also matters for cost control and scaling.","No billing in MVP; internal product for GL. MVP is your internal engine used to power DFY work, so you don’t implement pricing logic yet.","Hybrid model. Long term, you charge per seat (for workflow features) + per source or per signal volume + AI usage bands (for heavy WIM/AI-enhanced features)."
,65,Billing & Credits Model,Is WIM generation billable?,AI Cost Attribution,You need to know whether heavier AI features justify higher price tiers or usage limits.,"No. In MVP, WIM is just an internal cost absorbed into GL’s margins.","Yes, included in usage metrics. In the platform, WIM calls count towards AI usage, which influences pricing tiers and overage billing."
,66,Billing & Credits Model,Are rescrapes (manual refreshes) billable?,Abuse Prevention,Manual rescrapes can be spammed by users; billing or rate limits are needed.,Not in MVP. Manual rescrapes are limited operationally (GL triggers them rarely).,"Yes, tied to usage/credits. Later, manual rescrapes increment usage counters and might be rate-limited or require higher plans."
,67,Billing & Credits Model,What happens when a user runs out of credits/usage?,UX & Reliability,Running out of credits should not crash the product or suddenly hide critical data without explanation.,Not applicable in MVP. All usage is subscription  and not credit-based.,Graceful degradation. Platform users get warnings and soft limits; ingestion may slow or certain high-cost features (like fresh WIM) are disabled until usage resets or plan is upgraded.
,68,Billing & Credits Model,What uptime and latency targets are required?,SLA & Hosting,SLAs influence your infra choices and pricing. MVP may be informal; enterprises expect 99.9%+.,No formal SLA; best-effort uptime. You use reliable hosting but make no contractual promises.,"Defined SLA (e.g., 99.9% uptime) for enterprise tiers. You adjust infra for redundancy and monitoring to meet this."
,69,Operational & SLA Questions,What is the SLA for adding new sources?,Service Promise,Defining an SLA sets expectations and influences your internal ops workload.,"No formal SLA, handled ad hoc. GL negotiates expectations directly with clients.","Yes, e.g., 48 hours for supported geos and formats. This becomes part of your productised offering and contract."
,70,Operational & SLA Questions,Should broken scrapers automatically alert the team?,Monitoring,"Without alerting, broken feeds can silently rot your product.",Internal logging only. MVP relies on manual checks by devs/GL to spot issues.,Automated alerting and dashboards. You set up robust monitoring that triggers alerts and visual feed status indicators.
,71,Operational & SLA Questions,Who maintains scrapers long-term?,Ownership & Cost,"Scrapers are not “build once and forget”; they’re living assets that break frequently. You must decide if devs, a dedicated ops team, or a partner owns them.",Developer or small central GL tech team. MVP maintenance is manual and limited in scope.,"Dedicated “data/sources” team or vendor. At scale, you either hire a specific team or partner to handle source upkeep, possibly with internal tooling to accelerate."
,72,Operational & SLA Questions,How do we handle rate limits and blocking by sites?,Compliance & Reliability,Aggressive scraping can get IPs blocked and may violate terms; careful rate-limiting is required.,Basic rate limiting per host. MVP uses simple delays and respects robots.txt where appropriate.,"Sophisticated rate limiting and queuing. Later, you add backoff logic, concurrent job management, and possibly proxy infrastructure while remaining compliant."
,73,Operational & SLA Questions,Is SOC 2/ISO compliance needed?,Enterprise Readiness,"Compliance influences audit logging, security posture, and sales cycles in enterprise.",Not needed in MVP,"Yes for enterprise expansion. Over time, you design processes and architecture to meet SOC 2/ISO and bake compliance into your roadmap."
,74,Compliance & Legal,How long are logs and data retained?,Governance & Costs,Retention affects storage costs and legal risk; some customers demand defined retention policies.,"Short retention, e.g., 90 days for raw logs. MVP keeps just enough for debugging and no formal retention policy.","Configurable retention windows. The platform supports tenant-level config (e.g., 90/180/365 days) and data export before purge."
,75,Compliance & Legal,How do we handle geos where scraping is restricted?,Legal & Product Scope,Some jurisdictions or sites have stricter rules; your product must adapt or be geofenced.,Avoid obviously restricted geos/sources. MVP focuses on AU/US public sources with low legal complexity.,"Geo-aware enabling/disabling of sources. Later, you handle per-country legality and only enable certain data streams in compliant geos."
,76,Compliance & Legal,Will customers upload personal data (PII)?,Privacy & Architecture,PII triggers data protection obligations; avoiding it reduces compliance burden early on.,No PII in MVP. Signals are at account/project level; no humans/contact details stored.,"Yes potentially, in Phase 3+ when integrating with CRMs or enrichment. Then you must apply stronger security and privacy controls."
,77,Compliance & Legal,"Will the system store contact-level data (emails, phone numbers)?",PII Model,This determines whether you’re a “data controller” for personal data in many regimes.,"No for MVP. You only deal with companies, projects, and signals, not individual people.","Yes when AISDR and enrichment are integrated. Later, you ingest or enrich contacts, making you an actual CRM-adjacent system with PII responsibilities."
,78,Compliance & Legal,Are CRM integrations read-only or bi-directional?,Data Sync Architecture,Read-only is simpler and safer; bi-directional allows deeper workflows but introduces complexity and data ownership issues.,MVP: read-only deep links only and ability to export to CSV and Google Sheets,"Bi-directional sync for certain fields. Eventually, you push tasks, tags, and maybe timeline events into CRM while pulling account context back into SignalOS."